{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install opencv-python\n",
        "!pip install shapely\n",
        "!pip install geopandas\n",
        "!pip install rasterio\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "\n",
        "# Import modules\n",
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.plot import show\n",
        "from rasterio.mask import mask\n",
        "from rasterio.warp import transform, transform_bounds\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import cv2\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "i3a9rk_uF5Y2"
      },
      "id": "i3a9rk_uF5Y2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c4ddc9c-e314-4bf6-bb9f-7e99c0b86b12",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "8c4ddc9c-e314-4bf6-bb9f-7e99c0b86b12"
      },
      "outputs": [],
      "source": [
        "# Define base directory and years\n",
        "base_dir = \"D:/Sushrut\"\n",
        "years = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
        "scale_factor = 0.001  # MODIS scale factor\n",
        "fill_value = -28672  # MODIS fill value\n",
        "valid_range = (-100, 5000)  # Valid AOD range\n",
        "\n",
        "# Process each year\n",
        "for year in years:\n",
        "    print(f\"\\n Processing Year: {year}...\")\n",
        "\n",
        "    aod_folder = os.path.join(base_dir, year, \"AOD_047\")\n",
        "    qa_folder = os.path.join(base_dir, year, \"QA\")\n",
        "    output_folder = os.path.join(base_dir, year, \"Filtered_AOD_047\")\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Find all AOD files\n",
        "    aod_files = sorted(glob(os.path.join(aod_folder, \"*.tif\")))\n",
        "\n",
        "    if not aod_files:\n",
        "        print(f\"️ No AOD files found in {aod_folder}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    for aod_file in aod_files:\n",
        "        # Extract date from filename (e.g., A2024001)\n",
        "        date_str = os.path.basename(aod_file).split(\".\")[1]\n",
        "\n",
        "        # Find corresponding QA file\n",
        "        qa_files = glob(os.path.join(qa_folder, f\"*{date_str}*AOD_QA*.tif\"))\n",
        "        if not qa_files:\n",
        "            print(f\"️ No QA file found for {date_str} in {year}. Skipping...\")\n",
        "            continue\n",
        "        qa_file = qa_files[0]  # Select the first match\n",
        "\n",
        "        # Read AOD file\n",
        "        with rasterio.open(aod_file) as src:\n",
        "            aod_data = src.read(1).astype(np.float32)\n",
        "            meta = src.meta\n",
        "\n",
        "        # Handle fill values (-28672 → NaN)\n",
        "        aod_data[aod_data == fill_value] = np.nan\n",
        "\n",
        "        # Apply scale factor only to valid AOD values (-100 to 5000)\n",
        "        valid_mask = (aod_data >= valid_range[0]) & (aod_data <= valid_range[1])\n",
        "        aod_data = np.where(valid_mask, aod_data * scale_factor, np.nan)\n",
        "\n",
        "        # Read QA file\n",
        "        with rasterio.open(qa_file) as src:\n",
        "            qa_data = src.read(1).astype(np.uint16)\n",
        "\n",
        "        # Apply QA Masking (Keep Best, Moderate & Lower Confidence Pixels)\n",
        "        qa_bits = np.bitwise_and(qa_data, 3)  # Extract bits 0-1 (AOD Quality)\n",
        "        qa_valid_mask = (qa_bits == 3) | (qa_bits == 2) | (qa_bits == 1)\n",
        "\n",
        "        # Apply QA mask\n",
        "        filtered_data = np.where(qa_valid_mask, aod_data, np.nan)\n",
        "\n",
        "        # Save filtered AOD file\n",
        "        output_file = os.path.join(output_folder, f\"Filtered_AOD_{date_str}.tif\")\n",
        "        meta.update(dtype=rasterio.float32, nodata=np.nan)\n",
        "\n",
        "        with rasterio.open(output_file, \"w\", **meta) as dst:\n",
        "            dst.write(filtered_data, 1)\n",
        "\n",
        "        print(f\" Filtered AOD file saved for {date_str} in {year}: {output_file}\")\n",
        "\n",
        "print(\"\\n QA Masking Complete for All Years!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c314a4c2-04c4-4637-a00e-1edf287ad838",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "c314a4c2-04c4-4637-a00e-1edf287ad838"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define base directory and years\n",
        "base_dir = \"D:/Sushrut\"\n",
        "years = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
        "\n",
        "# Process each year\n",
        "for year in years:\n",
        "    print(f\"\\n Processing Year: {year}...\")\n",
        "\n",
        "    filtered_folder = os.path.join(base_dir, year, \"Filtered_AOD_047\")\n",
        "    output_folder = os.path.join(base_dir, year, \"Merged_AOD_047\")\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Find all filtered AOD files\n",
        "    filtered_files = sorted(glob(os.path.join(filtered_folder, \"*.tif\")))\n",
        "\n",
        "    if not filtered_files:\n",
        "        print(f\"️ No filtered AOD files found in {filtered_folder}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Group files by date\n",
        "    file_dict = {}\n",
        "    for file in filtered_files:\n",
        "        date_str = os.path.basename(file).split(\"_\")[2].split(\".\")[0]  # FIX: Remove extra \".tif\"\n",
        "        if date_str not in file_dict:\n",
        "            file_dict[date_str] = []\n",
        "        file_dict[date_str].append(file)\n",
        "\n",
        "    # Process each date\n",
        "    for date, file_list in file_dict.items():\n",
        "        print(f\" Merging {len(file_list)} AOD files for {date}...\")\n",
        "\n",
        "        # Open first file to get metadata\n",
        "        with rasterio.open(file_list[0]) as src:\n",
        "            meta = src.meta\n",
        "            meta.update(dtype=rasterio.float32, nodata=np.nan)\n",
        "            height, width = src.shape\n",
        "\n",
        "        # Create an empty stack to hold all AOD files for this date\n",
        "        data_stack = np.full((len(file_list), height, width), np.nan, dtype=np.float32)\n",
        "\n",
        "        # Load all AOD files for this date\n",
        "        for i, file in enumerate(file_list):\n",
        "            with rasterio.open(file) as src:\n",
        "                data_stack[i] = src.read(1)  # Read band 1\n",
        "\n",
        "        # Merge by taking the first valid value (or mean if needed)\n",
        "        merged_data = np.nanmean(data_stack, axis=0)  # Mean of available data\n",
        "\n",
        "        # Save merged file\n",
        "        output_file = os.path.join(output_folder, f\"Merged_AOD_{date}.tif\")\n",
        "        with rasterio.open(output_file, \"w\", **meta) as dst:\n",
        "            dst.write(merged_data.astype(rasterio.float32), 1)\n",
        "\n",
        "        print(f\" Merged AOD file saved for {date}: {output_file}\")\n",
        "\n",
        "print(\"\\n Merging Complete for All Years!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f966de8-c79b-4cd3-b069-f2b7e7e5258a",
      "metadata": {
        "id": "7f966de8-c79b-4cd3-b069-f2b7e7e5258a"
      },
      "outputs": [],
      "source": [
        "from scipy.interpolate import UnivariateSpline\n",
        "import numpy as np\n",
        "\n",
        "def apply_spline_smoothing(aod_data, dates, smoothing_factor=1.0):\n",
        "\n",
        "    smoothed_data = np.full_like(aod_data, np.nan)\n",
        "\n",
        "    for i in range(aod_data.shape[1]):  # Loop over pixels (columns)\n",
        "        for j in range(aod_data.shape[2]):  # Loop over pixels (rows)\n",
        "            pixel_values = aod_data[:, i, j]\n",
        "\n",
        "            # Find valid (non-NaN) indices\n",
        "            valid_idx = ~np.isnan(pixel_values)\n",
        "\n",
        "            if np.sum(valid_idx) > 5:  # At least 5 valid values needed\n",
        "                x = dates[valid_idx]\n",
        "                y = pixel_values[valid_idx]\n",
        "\n",
        "                #  Log-transform to stabilize large variations\n",
        "                y_log = np.log1p(y)\n",
        "\n",
        "                #  Apply smoothing spline with adjusted parameters\n",
        "                spline = UnivariateSpline(x, y_log, s=smoothing_factor)\n",
        "\n",
        "                #  Compute smoothed values and inverse log-transform\n",
        "                smoothed_values = np.expm1(spline(dates))\n",
        "\n",
        "                #  Clip values to realistic range (0 to 5)\n",
        "                smoothed_data[:, i, j] = np.clip(smoothed_values, 0, 5)\n",
        "\n",
        "    return smoothed_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10027057-13cd-4e58-8543-916636feb4d8",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "10027057-13cd-4e58-8543-916636feb4d8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define base directory\n",
        "base_dir = \"D:/Sushrut\"\n",
        "years = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
        "\n",
        "# Output folders\n",
        "smoothed_dir = \"Smoothed_Trend_AOD\"\n",
        "residual_dir = \"Residual_AOD\"\n",
        "\n",
        "# Process each year\n",
        "for year in years:\n",
        "    print(f\"\\n Processing Temporal Gap-Filling for Year: {year}...\")\n",
        "\n",
        "    merged_aod_dir = os.path.join(base_dir, year, \"Merged_AOD_047\")\n",
        "    smoothed_aod_dir = os.path.join(base_dir, year, smoothed_dir)\n",
        "    residual_aod_dir = os.path.join(base_dir, year, residual_dir)\n",
        "\n",
        "    # Create output folders\n",
        "    os.makedirs(smoothed_aod_dir, exist_ok=True)\n",
        "    os.makedirs(residual_aod_dir, exist_ok=True)\n",
        "\n",
        "    # Get all merged AOD files\n",
        "    merged_files = sorted([f for f in os.listdir(merged_aod_dir) if f.endswith(\".tif\")])\n",
        "\n",
        "    if not merged_files:\n",
        "        print(f\"️ No Merged AOD files found for {year}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Extract Dates from Filenames\n",
        "    dates = []\n",
        "    file_paths = []\n",
        "\n",
        "    for file in merged_files:\n",
        "        try:\n",
        "            date_str = os.path.basename(file).replace(\"Merged_AOD_A\", \"\").replace(\".tif\", \"\")\n",
        "            dates.append(int(date_str))  # Convert to integer\n",
        "            file_paths.append(os.path.join(merged_aod_dir, file))\n",
        "        except Exception as e:\n",
        "            print(f\"️ Skipping file: {file} (Invalid Date Format)\")\n",
        "\n",
        "    # Check if any valid files were found\n",
        "    if not file_paths:\n",
        "        print(f\" No valid files found for {year}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Sort by date\n",
        "    sorted_indices = np.argsort(dates)\n",
        "    dates = np.array(dates)[sorted_indices]\n",
        "    file_paths = [file_paths[i] for i in sorted_indices]\n",
        "\n",
        "    # Read first file to get metadata\n",
        "    with rasterio.open(file_paths[0]) as src:\n",
        "        height, width = src.shape\n",
        "        meta = src.meta\n",
        "        meta.update(dtype=rasterio.float32, nodata=np.nan)\n",
        "\n",
        "    # Load all AOD files into memory\n",
        "    print(\" Loading AOD data into memory...\")\n",
        "    aod_data = np.full((len(dates), height, width), np.nan, dtype=np.float32)\n",
        "\n",
        "    for i, file in enumerate(file_paths):\n",
        "        with rasterio.open(file) as src:\n",
        "            aod_data[i] = src.read(1)\n",
        "\n",
        "    # Process row-wise\n",
        "    print(\" Applying Smoothing Spline...\")\n",
        "    smoothed_data = np.full_like(aod_data, np.nan, dtype=np.float32)\n",
        "    residuals_data = np.full_like(aod_data, np.nan, dtype=np.float32)\n",
        "\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            pixel_values = aod_data[:, i, j]\n",
        "            valid_idx = ~np.isnan(pixel_values)\n",
        "\n",
        "            if np.sum(valid_idx) > 10:  # Apply smoothing only if sufficient data exists\n",
        "                x = dates[valid_idx]\n",
        "                y = pixel_values[valid_idx]\n",
        "                spline = UnivariateSpline(x, y, s=0.5)  # Smoothing spline\n",
        "                smoothed_values = spline(dates)\n",
        "            else:\n",
        "                smoothed_values = np.full_like(dates, np.nan, dtype=np.float32)\n",
        "\n",
        "            # Compute residuals (Original - Smoothed Trend)\n",
        "            smoothed_data[:, i, j] = smoothed_values\n",
        "            residuals_data[:, i, j] = pixel_values - smoothed_values\n",
        "\n",
        "    # Save Smoothed AOD & Residuals as GeoTIFFs\n",
        "    for k, date in enumerate(dates):\n",
        "        smoothed_file = os.path.join(smoothed_aod_dir, f\"Smoothed_Trend_AOD_A{date}.tif\")\n",
        "        residual_file = os.path.join(residual_aod_dir, f\"Residual_AOD_A{date}.tif\")\n",
        "\n",
        "        with rasterio.open(smoothed_file, \"w\", **meta) as dst:\n",
        "            dst.write(smoothed_data[k], 1)\n",
        "\n",
        "        with rasterio.open(residual_file, \"w\", **meta) as dst:\n",
        "            dst.write(residuals_data[k], 1)\n",
        "\n",
        "        print(f\" Saved: {smoothed_file}, {residual_file}\")\n",
        "\n",
        "print(\"\\n Temporal Gap-Filling & Smoothing Complete for All Years!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce8db90-bc98-4985-89e4-0e046cc2ce39",
      "metadata": {
        "id": "0ce8db90-bc98-4985-89e4-0e046cc2ce39"
      },
      "outputs": [],
      "source": [
        "#  Define Paths\n",
        "input_folder = \"D:/Sushrut/2024/Residual_AOD\"  # Input folder of having Residual_AOD\n",
        "output_folder = \"D:/Sushrut/2024/Cropped_AOD_Files\"  # Output folder for cropped files\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "#  Define Bounding Box\n",
        "bbox = box(77.8889, 17.0780, 78.7735, 17.8714)\n",
        "bbox_gdf = gpd.GeoDataFrame({\"geometry\": [bbox]}, crs=\"EPSG:4326\")\n",
        "\n",
        "#  Step 1: Loop through all GeoTIFF files in the folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".tif\"):\n",
        "        input_raster = os.path.join(input_folder, filename)\n",
        "        output_raster = os.path.join(output_folder, filename)\n",
        "\n",
        "        with rasterio.open(input_raster) as src:\n",
        "            bbox_proj = bbox_gdf.to_crs(src.crs)  # Convert bounding box to raster CRS\n",
        "            out_image, out_transform = mask(src, bbox_proj.geometry, crop=True, nodata=np.nan)\n",
        "            out_meta = src.meta.copy()\n",
        "\n",
        "        #  Step 2: Save Cropped Raster\n",
        "        out_meta.update({\"driver\": \"GTiff\", \"height\": out_image.shape[1],\n",
        "                         \"width\": out_image.shape[2], \"transform\": out_transform})\n",
        "\n",
        "        with rasterio.open(output_raster, \"w\", **out_meta) as dst:\n",
        "            dst.write(out_image)\n",
        "\n",
        "        print(f\" Cropped: {filename}\")\n",
        "\n",
        "print(\" All Residual AOD Files Cropped Successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Define Paths\n",
        "base_dir = \"D:/Sushrut/2024/Cropped_AOD_Files\"  # Directory containing residual AOD files\n",
        "output_dir = \"D:/Sushrut/2024/High_Quality_Files\"  # Destination folder\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#  Find all residual AOD files\n",
        "residual_files = sorted(glob(os.path.join(base_dir, \"*.tif\")))\n",
        "\n",
        "#  Debugging: Track file counts\n",
        "total_files = len(residual_files)\n",
        "copied_files = 0\n",
        "skipped_files = 0\n",
        "\n",
        "print(f\" Total Residual AOD Files Found: {total_files}\")\n",
        "\n",
        "#  Process each file\n",
        "for file in residual_files:\n",
        "    try:\n",
        "        with rasterio.open(file) as src:\n",
        "            data = src.read(1)  # Read the raster data\n",
        "            total_pixels = data.size\n",
        "            nan_pixels = np.count_nonzero(np.isnan(data))\n",
        "            nan_percentage = (nan_pixels / total_pixels) * 100\n",
        "\n",
        "        #  Copy file if NaN percentage is <50%\n",
        "        if nan_percentage < 50:\n",
        "            dest_path = os.path.join(output_dir, os.path.basename(file))\n",
        "            shutil.copy2(file, dest_path)  # Copy file instead of moving\n",
        "            copied_files += 1\n",
        "            print(f\" Copied: {file} | NaN%: {nan_percentage:.2f}\")\n",
        "        else:\n",
        "            skipped_files += 1\n",
        "            print(f\"️ Skipped: {file} | NaN%: {nan_percentage:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error reading {file}: {e}\")\n",
        "        skipped_files += 1\n",
        "\n",
        "#  Summary\n",
        "print(\"\\n **Final Report:**\")\n",
        "print(f\" Successfully copied {copied_files} files with <50% NaN to {output_dir}.\")\n",
        "print(f\"️ Skipped {skipped_files} files due to >50% NaN or errors.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IF6I0nl3AQ2-"
      },
      "id": "IF6I0nl3AQ2-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  Define Paths\n",
        "high_quality_dir = \"D:/Sushrut/2024/High_Quality_Files\"  # High-quality files\n",
        "output_dir = \"D:/Sushrut/2024/Interpolated_AOD\"  # Output directory\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#  Get all high-quality files\n",
        "high_quality_files = sorted(glob(os.path.join(high_quality_dir, \"*.tif\")))\n",
        "\n",
        "#  Function to Perform Bilinear Interpolation\n",
        "def bilinear_interpolation(input_file, output_file):\n",
        "    with rasterio.open(input_file) as src:\n",
        "        data = src.read(1)  # Read the single-band raster\n",
        "        meta = src.meta.copy()\n",
        "\n",
        "    # Convert NaNs to OpenCV-compatible format (-9999 for missing values)\n",
        "    data[np.isnan(data)] = -9999\n",
        "\n",
        "    # Apply Bilinear Interpolation using OpenCV (INPAINT_TELEA for better edge recovery)\n",
        "    interpolated_data = cv2.inpaint(data.astype(np.float32), (data == -9999).astype(np.uint8), 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "    # Restore NaN values to interpolated areas\n",
        "    interpolated_data[data == -9999] = np.nan\n",
        "\n",
        "    # Save the interpolated raster\n",
        "    with rasterio.open(output_file, \"w\", **meta) as dst:\n",
        "        dst.write(interpolated_data.astype(rasterio.float32), 1)\n",
        "\n",
        "    print(f\" Interpolated & Saved: {output_file}\")\n",
        "\n",
        "#  Process Each High-Quality File\n",
        "for file in high_quality_files:\n",
        "    output_file = os.path.join(output_dir, os.path.basename(file))\n",
        "    bilinear_interpolation(file, output_file)\n",
        "\n",
        "print(\"\\n Spatial Interpolation Completed for High-Quality Files!\")\n"
      ],
      "metadata": {
        "id": "JkYPacN_GpHe"
      },
      "id": "JkYPacN_GpHe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Define Paths\n",
        "smoothed_trend_dir = \"D:/Sushrut/2024/Smoothed_Trend_AOD\"\n",
        "output_dir = \"D:/Sushrut/2024/Cropped_Smoothed_Trend_AOD\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "#  Bounding Box in EPSG:4326 (WGS84)\n",
        "xmin, ymin = 77.8889473735543, 17.078092493133276\n",
        "xmax, ymax = 78.77358882331039, 17.87442882026007851\n",
        "\n",
        "#  Check CRS of Raster\n",
        "sample_file = glob(os.path.join(smoothed_trend_dir, \"*.tif\"))[0]\n",
        "with rasterio.open(sample_file) as src:\n",
        "    raster_crs = src.crs\n",
        "    raster_bounds = src.bounds\n",
        "\n",
        "    # Convert Bounding Box to Match Raster CRS\n",
        "    if raster_crs != \"EPSG:4326\":\n",
        "        xmin, ymin, xmax, ymax = transform_bounds(\"EPSG:4326\", raster_crs, xmin, ymin, xmax, ymax)\n",
        "\n",
        "#  Create Bounding Box with Updated CRS\n",
        "bbox = box(xmin, ymin, xmax, ymax)\n",
        "\n",
        "#  Function to Crop GeoTIFF\n",
        "def crop_geotiff(input_file, output_file, bounding_box):\n",
        "    with rasterio.open(input_file) as src:\n",
        "        # Crop using bounding box\n",
        "        try:\n",
        "            out_image, out_transform = mask(src, [bounding_box], crop=True, nodata=np.nan)\n",
        "        except ValueError as e:\n",
        "            print(f\"️ Skipping {input_file}: {e}\")\n",
        "            return  # Skip files that don't intersect\n",
        "\n",
        "        out_meta = src.meta.copy()\n",
        "        out_meta.update({\n",
        "            \"height\": out_image.shape[1],\n",
        "            \"width\": out_image.shape[2],\n",
        "            \"transform\": out_transform\n",
        "        })\n",
        "\n",
        "        # Save cropped raster\n",
        "        with rasterio.open(output_file, \"w\", **out_meta) as dst:\n",
        "            dst.write(out_image)\n",
        "\n",
        "    print(f\" Cropped & Saved: {output_file}\")\n",
        "\n",
        "#  Process Each Smoothed Trend AOD File\n",
        "smoothed_trend_files = sorted(glob(os.path.join(smoothed_trend_dir, \"*.tif\")))\n",
        "\n",
        "for file in smoothed_trend_files:\n",
        "    output_file = os.path.join(output_dir, os.path.basename(file))\n",
        "    crop_geotiff(file, output_file, bbox)\n",
        "\n",
        "print(\"\\n Cropping Completed for Smoothed Trend AOD Files!\")"
      ],
      "metadata": {
        "id": "pd98LENsGzB3"
      },
      "id": "pd98LENsGzB3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#  Base Directory\n",
        "base_dir = \"D:/Sushrut\"\n",
        "year = \"2020\"  # Process only for 2020\n",
        "\n",
        "print(f\"\\n Processing Year: {year}...\")\n",
        "\n",
        "#  Define paths\n",
        "high_quality_dir = os.path.join(base_dir, year, \"High_Quality_Files\")\n",
        "smoothed_trend_dir = os.path.join(base_dir, year, \"Cropped_Smoothed_Trend_AOD\")\n",
        "final_smoothed_dir = os.path.join(base_dir, year, \"Final_Smoothed_AOD\")\n",
        "\n",
        "os.makedirs(final_smoothed_dir, exist_ok=True)\n",
        "\n",
        "#  Step 1: Extract Dates from High-Quality Files\n",
        "high_quality_files = glob(os.path.join(high_quality_dir, \"*.tif\"))\n",
        "\n",
        "high_quality_dates = set()\n",
        "for file in high_quality_files:\n",
        "    filename = os.path.basename(file)\n",
        "    if \"_A\" in filename:\n",
        "        date_part = filename.split(\"_A\")[1].split(\".tif\")[0]  # Extract YYYYDDD\n",
        "        if date_part.isdigit():  # Ensure it's a valid date\n",
        "            high_quality_dates.add(date_part)\n",
        "\n",
        "print(f\"    High-Quality Files Found: {len(high_quality_files)}\")\n",
        "print(f\"    Unique Dates in High-Quality Files: {sorted(high_quality_dates)}\")\n",
        "\n",
        "#  Step 2: Copy Matching Smoothed AOD Files\n",
        "smoothed_files = glob(os.path.join(smoothed_trend_dir, \"*.tif\"))\n",
        "copied_files = 0\n",
        "\n",
        "for file in smoothed_files:\n",
        "    file_date = os.path.basename(file).split(\"_A\")[1].split(\".tif\")[0]\n",
        "\n",
        "    if file_date in high_quality_dates:  #  Only copy if date exists in High-Quality Files\n",
        "        shutil.copy(file, os.path.join(final_smoothed_dir, os.path.basename(file)))\n",
        "        copied_files += 1\n",
        "    else:\n",
        "        print(f\"    Skipping {os.path.basename(file)} (No Matching High-Quality File)\")\n",
        "\n",
        "print(f\"\\n Copied {copied_files} Smoothed Trend AOD files to {final_smoothed_dir}.\")\n",
        "print(\"\\n Process Complete for Year 2020!\")\n"
      ],
      "metadata": {
        "id": "NZrJ7m4RHE7W"
      },
      "id": "NZrJ7m4RHE7W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Parameters\n",
        "base_dir = \"D:/Sushrut\"\n",
        "year = \"2024\"  # Change year if needed\n",
        "\n",
        "# Input folders\n",
        "smoothed_folder = os.path.join(base_dir, year, \"Final_Smoothed_AOD\")\n",
        "residual_folder = os.path.join(base_dir, year, \"Interpolated_AOD\")\n",
        "\n",
        "# Output folder\n",
        "output_folder = os.path.join(base_dir, year, \"Processed_GapFilled_AOD\")\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Get all input files sorted by date\n",
        "smoothed_files = sorted(glob(os.path.join(smoothed_folder, \"*.tif\")))\n",
        "residual_files = sorted(glob(os.path.join(residual_folder, \"*.tif\")))\n",
        "\n",
        "# Check matching counts\n",
        "if len(smoothed_files) != len(residual_files):\n",
        "    print(\"Warning: Number of smoothed and residual files do not match!\")\n",
        "    print(f\"Smoothed: {len(smoothed_files)}, Residuals: {len(residual_files)}\")\n",
        "\n",
        "# Combine and save\n",
        "for smooth_file, residual_file in zip(smoothed_files, residual_files):\n",
        "    # Extract date string from file\n",
        "    date_str = os.path.basename(smooth_file).split(\"_A\")[1].split(\".tif\")[0]\n",
        "\n",
        "    # Read rasters\n",
        "    with rasterio.open(smooth_file) as src_smooth:\n",
        "        smooth_data = src_smooth.read(1).astype(np.float32)\n",
        "        meta = src_smooth.meta.copy()\n",
        "\n",
        "    with rasterio.open(residual_file) as src_res:\n",
        "        residual_data = src_res.read(1).astype(np.float32)\n",
        "\n",
        "    # Compute Final Gap-Filled AOD\n",
        "    gapfilled_data = smooth_data + residual_data\n",
        "\n",
        "    # Clip to realistic range (0–5)\n",
        "    gapfilled_data = np.clip(gapfilled_data, 0, 5)\n",
        "\n",
        "    # Update metadata and save\n",
        "    meta.update(dtype=rasterio.float32, nodata=np.nan)\n",
        "    output_file = os.path.join(output_folder, f\"GapFilled_AOD_A{date_str}.tif\")\n",
        "\n",
        "    with rasterio.open(output_file, \"w\", **meta) as dst:\n",
        "        dst.write(gapfilled_data, 1)\n",
        "\n",
        "    print(f\"Saved: {output_file}\")\n",
        "\n",
        "print(\"All Final Gap-Filled AOD files generated.\")"
      ],
      "metadata": {
        "id": "MKUUqtZCHLGV"
      },
      "id": "MKUUqtZCHLGV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Base Directory\n",
        "base_dir = \"C:/SushrutK\"\n",
        "years = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
        "\n",
        "# Sampling Locations (Geographic CRS: EPSG:4326)\n",
        "locations = {\n",
        "    \"Bollaram_Industrial Area\": (78.358528, 17.540891),\n",
        "    \"Hyderabad Central University\": (78.334361, 17.460103),\n",
        "    \"US Consulate\": (78.3310916, 17.4248562),\n",
        "    \"ICRISAT\": (78.278777, 17.518400),\n",
        "    \"Kokapet\": (78.339194, 17.393559),\n",
        "    \"Sanathnagar\": (78.4439295, 17.4562544),\n",
        "    \"Somajiguda\": (78.457437, 17.417094),\n",
        "    \"Zoo Park, Bahadurpura West\": (78.451437, 17.349694),\n",
        "    \"New Malkapet\": (78.50864, 17.37206),\n",
        "    \"IIT, Hyderabad\": (78.126199, 17.585705),\n",
        "    \"Nacharam TSIIC-IALA\": (78.569354, 17.429398),\n",
        "    \"ECII- Kapra, Hyderabad\": (78.566959, 17.470431),\n",
        "    \"Komapally Municipal Office\": (78.486949, 17.544899),\n",
        "    \"Ramachandrapuram\": (78.286195, 17.528544),\n",
        "    \"Pashamylaram\": (78.218939, 17.5316895),\n",
        "}\n",
        "\n",
        "# Initialize dictionary to store data\n",
        "data_dict = {}\n",
        "\n",
        "# Process Each Year\n",
        "for year in years:\n",
        "    input_folder = os.path.join(base_dir, year, \"Processed_GapFilled_AOD\")\n",
        "    tiff_files = sorted(glob(os.path.join(input_folder, \"GapFilled_AOD_*.tif\")))\n",
        "\n",
        "    for tiff in tiff_files:\n",
        "        # Extract date from filename\n",
        "        date_str = os.path.basename(tiff).split(\"_\")[-1].split(\".tif\")[0]  # Extract YYYYDDD\n",
        "\n",
        "        with rasterio.open(tiff) as src:\n",
        "            raster_crs = src.crs  # Get raster CRS\n",
        "\n",
        "            # Convert Geographic Coordinates to Raster CRS\n",
        "            lons, lats = zip(*locations.values())\n",
        "            utm_x, utm_y = transform(\"EPSG:4326\", raster_crs.to_string(), lons, lats)\n",
        "\n",
        "            # Initialize data for this date if not already present\n",
        "            if date_str not in data_dict:\n",
        "                data_dict[date_str] = {loc: None for loc in locations.keys()}\n",
        "\n",
        "            # Extract AOD Values\n",
        "            for loc_name, x, y in zip(locations.keys(), utm_x, utm_y):\n",
        "                try:\n",
        "                    row, col = src.index(x, y)  # Get row and col indices\n",
        "                    aod_value = src.read(1)[row, col]  # Read AOD Value\n",
        "                except IndexError:\n",
        "                    aod_value = None  # If outside bounds\n",
        "\n",
        "                # Store the AOD value for this location and date\n",
        "                data_dict[date_str][loc_name] = aod_value\n",
        "\n",
        "# Create DataFrame from extracted data\n",
        "dates = sorted(data_dict.keys())\n",
        "columns = [\"Date\"] + list(locations.keys())\n",
        "formatted_data = pd.DataFrame(columns=columns)\n",
        "\n",
        "for date in dates:\n",
        "    row = {\"Date\": date}\n",
        "    row.update(data_dict[date])\n",
        "    formatted_data = pd.concat([formatted_data, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "output_csv_path = os.path.join(base_dir, \"AOD_Extracted_Values27.csv\")\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "formatted_data.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\" AOD values saved to: {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "mIicFRENHRrO"
      },
      "id": "mIicFRENHRrO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (gdal_env)",
      "language": "python",
      "name": "gdal_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}